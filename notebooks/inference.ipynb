{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Alpamayo-R1 Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "This notebook will load some example data from the NVIDIA [PhysicalAI-AV Dataset](https://huggingface.co/datasets/nvidia/PhysicalAI-Autonomous-Vehicles) and run the Alpamayo-R1 model on it, producing and visualizing output trajectories and associated reasoning traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import mediapy as mp\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from alpamayo_r1.models.alpamayo_r1 import AlpamayoR1\n",
    "from alpamayo_r1.load_physical_aiavdataset import load_physical_aiavdataset\n",
    "from alpamayo_r1 import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Load model and construct data preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlpamayoR1.from_pretrained(\"nvidia/Alpamayo-R1-10B\", dtype=torch.bfloat16).to(\"cuda\")\n",
    "processor = helper.get_processor(model.tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_ids = pd.read_parquet(\"clip_ids.parquet\")[\"clip_id\"].tolist()\n",
    "clip_id = clip_ids[774]\n",
    "# clip_id = '030c760c-ae38-49aa-9ad8-f5650a545d26'\n",
    "\n",
    "data = load_physical_aiavdataset(clip_id)\n",
    "\n",
    "messages = helper.create_message(data[\"image_frames\"].flatten(0, 1))\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=False,\n",
    "    continue_final_message=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "print(\"seq length:\", inputs.input_ids.shape)\n",
    "model_inputs = {\n",
    "    \"tokenized_data\": inputs,\n",
    "    \"ego_history_xyz\": data[\"ego_history_xyz\"],\n",
    "    \"ego_history_rot\": data[\"ego_history_rot\"],\n",
    "}\n",
    "model_inputs = helper.to_device(model_inputs, \"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed_all(42)\n",
    "with torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "    pred_xyz, pred_rot, extra = model.sample_trajectories_from_data_with_vlm_rollout(\n",
    "        data=copy.deepcopy(model_inputs),\n",
    "        top_p=0.98,\n",
    "        temperature=0.6,\n",
    "        num_traj_samples=1,  # Feel free to raise this for more output trajectories and CoC traces.\n",
    "        max_generation_length=256,\n",
    "        return_extra=True,\n",
    "    )\n",
    "\n",
    "# the size is [batch_size, num_traj_sets, num_traj_samples]\n",
    "print(\"Chain-of-Causation (per trajectory):\\n\", extra[\"cot\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Visualizing data and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.show_images(data[\"image_frames\"].flatten(0, 1).permute(0, 2, 3, 1), columns=4, width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def rotate_90cc(xy):\n",
    "    # Rotate (x, y) by 90 deg CCW -> (y, -x)\n",
    "    return np.stack([-xy[1], xy[0]], axis=0)\n",
    "\n",
    "\n",
    "for i in range(pred_xyz.shape[2]):\n",
    "    pred_xy = pred_xyz.cpu()[0, 0, i, :, :2].T.numpy()\n",
    "    pred_xy_rot = rotate_90cc(pred_xy)\n",
    "    gt_xy = data[\"ego_future_xyz\"].cpu()[0, 0, :, :2].T.numpy()\n",
    "    gt_xy_rot = rotate_90cc(gt_xy)\n",
    "    plt.plot(*pred_xy_rot, \"o-\", label=f\"Predicted Trajectory #{i + 1}\")\n",
    "plt.ylabel(\"y coordinate (meters)\")\n",
    "plt.xlabel(\"x coordinate (meters)\")\n",
    "plt.plot(*gt_xy_rot, \"r-\", label=\"Ground Truth Trajectory\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.axis(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xy = pred_xyz.cpu().numpy()[0, 0, :, :, :2].transpose(0, 2, 1)\n",
    "diff = np.linalg.norm(pred_xy - gt_xy[None, ...], axis=1).mean(-1)\n",
    "print(\"minADE:\", diff.min(), \"meters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
